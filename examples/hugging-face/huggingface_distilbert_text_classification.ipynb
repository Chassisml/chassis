{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "978a16a1",
   "metadata": {},
   "source": [
    "## Chassis Example Notebooks\n",
    "Welcome to the examples section for [Chassis](https://chassis.ml), which contains notebooks that auto-containerize models built using the most common machine learning (ML) frameworks. \n",
    "\n",
    "#### What is Chassis?\n",
    "Chassis allows you to automatically create a Docker container from your model code and push that container image to a Docker registry. All you need is your model loaded into memory and a few lines of Chassis code! Our example bank is here to provide reference examples for many common ML frameworks.  \n",
    "\n",
    "Can't find the framework you are looking for or need help? Fork this repository and open a PR, or list the desired framework in a new issue. We're always interested in growing this example bank! \n",
    "\n",
    "The primary maintainers of Chassis also actively monitor our [Discord Server](https://discord.gg/cHpzY9yCcM), so feel free to join and ask any questions you might have. We'll be there to respond and help out promptly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b84583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import chassisml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b3bf0",
   "metadata": {},
   "source": [
    "## Enter credentials\n",
    "Dockerhub creds and Modzy API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b91d7099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker hub username········\n",
      "docker hub password········\n"
     ]
    }
   ],
   "source": [
    "dockerhub_user = getpass.getpass('docker hub username')\n",
    "dockerhub_pass = getpass.getpass('docker hub password')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963bb8ea",
   "metadata": {},
   "source": [
    "## Prepare model, labels, and data transform object\n",
    "Initialize anything here that should persist across inference runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7aa4e3",
   "metadata": {},
   "source": [
    "In this example, we will download this [DistilBERT](https://huggingface.co/bhadresh-savani/distilbert-base-uncased-emotion?text=I+like+you.+I+love+you) pretrained model. Modify the below import based on the \"Use in Transformers\" code for the model you wish to containerize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e344a526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f871c6803376486b92bbb4674e04ac6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c9afde4def419980b8da1f384c3eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/768 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8dc856fa61140dfa1b71dd914ed946f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c7293053c24098852d1736528c741b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad97d4896fa74d21b71a5ef14f2b58d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download model with the transformers library\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bhadresh-savani/distilbert-base-uncased-emotion\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bhadresh-savani/distilbert-base-uncased-emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8a688fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we save model locally so we can load it into memory for use with Chassis package\n",
    "tokenizer.save_pretrained(\"./model\")\n",
    "model.save_pretrained(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0afa5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model into memory from local file\n",
    "distilbert_tokenizer = AutoTokenizer.from_pretrained(\"./model\")\n",
    "distilbert_model = AutoModelForSequenceClassification.from_pretrained(\"./model\")\n",
    "\n",
    "# define labels from model config\n",
    "labels = model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78484375",
   "metadata": {},
   "source": [
    "## Write process function\n",
    "\n",
    "* Must take bytes as input\n",
    "* Preprocess bytes, run inference, postprocess model output, return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32674a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define process function that will serve as our inference function\n",
    "def process(input_bytes):\n",
    "    # decode and preprocess data bytes\n",
    "    text = input_bytes.decode()\n",
    "    inputs = distilbert_tokenizer(text, return_tensors=\"pt\")\n",
    "    \n",
    "    # run preprocessed data through model\n",
    "    with torch.no_grad():\n",
    "        logits = distilbert_model(**inputs).logits\n",
    "        softmax = torch.nn.functional.softmax(logits, dim=1).detach().cpu().numpy()\n",
    "        \n",
    "    # postprocess \n",
    "    indices = np.argsort(softmax)[0][::-1]\n",
    "    results = {\n",
    "        \"data\": {\n",
    "            \"result\": {\n",
    "                \"classPredictions\": [{\"class\": labels[i], \"score\": softmax[0][i]} for i in indices]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad13cf1",
   "metadata": {},
   "source": [
    "## Initialize Chassis Client\n",
    "We'll use this to interact with the Chassis service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38060508",
   "metadata": {},
   "outputs": [],
   "source": [
    "chassis_client = chassisml.ChassisClient(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e2cbf",
   "metadata": {},
   "source": [
    "## Create and test Chassis model\n",
    "* Requires `process_fn` defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1214c956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"joy\",\"score\":0.9971561431884766},{\"class\":\"love\",\"score\":0.0008850579615682364},{\"class\":\"sadness\",\"score\":0.0008116100216284394},{\"class\":\"anger\",\"score\":0.0005449091549962759},{\"class\":\"surprise\",\"score\":0.00035346485674381256},{\"class\":\"fear\",\"score\":0.00024872180074453354}]}}}'\n"
     ]
    }
   ],
   "source": [
    "# create Chassis model\n",
    "chassis_model = chassis_client.create_model(process_fn=process)\n",
    "\n",
    "# test Chassis model (can pass filepath, bufferedreader, bytes, or text here):\n",
    "sample_filepath = './data/input.txt'\n",
    "results = chassis_model.test(sample_filepath)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6b3499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test environment and model within Chassis service, must pass filepath here:\n",
    "test_env_result = chassis_model.test_env(sample_filepath)\n",
    "print(test_env_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de8c023",
   "metadata": {},
   "source": [
    "## Publish model to Docker\n",
    "Need to provide model name, model version, and Dockerhub credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dfcbccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting build job... Ok!\n"
     ]
    }
   ],
   "source": [
    "response = chassis_model.publish(\n",
    "    model_name=\"Hugging Face DistilBERT\",\n",
    "    model_version=\"0.0.1\",\n",
    "    registry_user=dockerhub_user,\n",
    "    registry_pass=dockerhub_pass\n",
    ")\n",
    "\n",
    "job_id = response.get('job_id')\n",
    "final_status = chassis_client.block_until_complete(job_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
