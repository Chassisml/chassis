{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chassis Example Notebooks\n",
    "Welcome to the examples section for [Chassis](https://chassis.ml), which contains notebooks that auto-containerize models built using the most common machine learning (ML) frameworks. \n",
    "\n",
    "#### What is Chassis?\n",
    "Chassis allows you to automatically create a Docker container from your model code and push that container image to a Docker registry. All you need is your model loaded into memory and a few lines of Chassis code! Our example bank is here to provide reference examples for many common ML frameworks.  \n",
    "\n",
    "Can't find the framework you are looking for or need help? Fork this repository and open a PR, or list the desired framework in a new issue. We're always interested in growing this example bank! \n",
    "\n",
    "The primary maintainers of Chassis also actively monitor our [Discord Server](https://discord.gg/cHpzY9yCcM), so feel free to join and ask any questions you might have. We'll be there to respond and help out promptly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chassisml\n",
    "import numpy as np\n",
    "import getpass\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter credentials\n",
    "Dockerhub creds and Modzy API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dockerhub_user = getpass.getpass('docker hub username')\n",
    "dockerhub_pass = getpass.getpass('docker hub password')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression mean accuracy score: 0.933333\n"
     ]
    }
   ],
   "source": [
    "# Import and normalize data\n",
    "X_digits, y_digits = datasets.load_digits(return_X_y=True)\n",
    "X_digits = X_digits / X_digits.max()\n",
    "\n",
    "n_samples = len(X_digits)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train = X_digits[: int(0.9 * n_samples)]\n",
    "y_train = y_digits[: int(0.9 * n_samples)]\n",
    "X_test = X_digits[int(0.9 * n_samples) :]\n",
    "y_test = y_digits[int(0.9 * n_samples) :]\n",
    "\n",
    "# Train Model\n",
    "logistic = LogisticRegression(max_iter=1000)\n",
    "print(\n",
    "    \"LogisticRegression mean accuracy score: %f\"\n",
    "    % logistic.fit(X_train, y_train).score(X_test, y_test)\n",
    ")\n",
    "\n",
    "# Save small sample input to use for testing later\n",
    "sample = X_test[:5].tolist()\n",
    "with open(\"data/digits_sample.json\", 'w') as out:\n",
    "    json.dump(sample, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write process function\n",
    "\n",
    "* Must take bytes as input\n",
    "* Preprocess bytes, run inference, postprocess model output, return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(input_bytes):\n",
    "    inputs = np.array(json.loads(input_bytes))\n",
    "    inference_results = logistic.predict(inputs)\n",
    "    structured_results = []\n",
    "    for inference_result in inference_results:\n",
    "        structured_output = {\n",
    "            \"data\": {\n",
    "                \"result\": {\"classPredictions\": [{\"class\": str(inference_result), \"score\": str(1)}]}\n",
    "            }\n",
    "        }\n",
    "        structured_results.append(structured_output)\n",
    "    return structured_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Chassis Client\n",
    "We'll use this to interact with the Chassis service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chassis_client = chassisml.ChassisClient(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and test Chassis model\n",
    "* Requires `process_fn` defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"5\",\"score\":\"1\"}]}}},{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"2\",\"score\":\"1\"}]}}},{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"8\",\"score\":\"1\"}]}}},{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"0\",\"score\":\"1\"}]}}},{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"1\",\"score\":\"1\"}]}}}]'\n"
     ]
    }
   ],
   "source": [
    "# create Chassis model\n",
    "chassis_model = chassis_client.create_model(process_fn=process)\n",
    "\n",
    "# test Chassis model locally (can pass filepath, bufferedreader, bytes, or text here):\n",
    "sample_filepath = './data/digits_sample.json'\n",
    "results = chassis_model.test(sample_filepath)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually construct conda environment to pass to Chassis job\n",
    "\n",
    "# NOTE: if you define your environment manually like this, the \"chassisml\" package must be included within the pip depedencies\n",
    "env = {\n",
    "    \"name\": \"sklearn-chassis\",\n",
    "    \"channels\": ['conda-forge'],\n",
    "    \"dependencies\": [\n",
    "        \"python=3.8.5\",\n",
    "        {\n",
    "            \"pip\": [\n",
    "                \"scikit-learn\",\n",
    "                \"numpy\",\n",
    "                \"chassisml\"\n",
    "            ] \n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test job... Ok!\n",
      "{'model_output': 'Single input prediction:\\n\\nb\\'[{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"5\",\"score\":\"1\"}]}}},{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"2\",\"score\":\"1\"}]}}},{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"8\",\"score\":\"1\"}]}}},{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"0\",\"score\":\"1\"}]}}},{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"1\",\"score\":\"1\"}]}}}]\\'\\n'}\n"
     ]
    }
   ],
   "source": [
    "# test environment and model within Chassis service, must pass filepath here:\n",
    "\n",
    "# dry run before build\n",
    "test_env_result = chassis_model.test_env(test_input_path=sample_filepath, conda_env=env)\n",
    "print(test_env_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish model to Dockerhub\n",
    "Need to provide model name, model version, Dockerhub credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chassis_model.publish(\n",
    "    model_name=\"Sklearn Logistic Regression Digits Image Classification\",\n",
    "    model_version=\"0.0.2\",\n",
    "    registry_user=dockerhub_user,\n",
    "    registry_pass=dockerhub_pass,\n",
    "    conda_env=env\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = response.get('job_id')\n",
    "final_status = chassis_client.block_until_complete(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model URL: https://demo.modzy.engineering/models/i6ugw0hl96/0.0.2\n"
     ]
    }
   ],
   "source": [
    "if final_status[\"result\"] is not None:\n",
    "    print(\"New model URL: {}\".format(final_status[\"result\"][\"container_url\"]))\n",
    "else:\n",
    "    print(\"Chassis job failed \\n\\n {}\".format(final_status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95ab8d3bdd708a5b71676285742277315a30b0df1ed91c8905076616709c59d5"
  },
  "kernelspec": {
   "display_name": "chassis-demo-1",
   "language": "python",
   "name": "chassis-demo-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
