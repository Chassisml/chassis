{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chassisml Example Notebooks\n",
    "Welcome to the examples section for [Chassis.ml](https://chassis.ml), which contains notebooks that leverage Chassisml to auto-containerize models built using the most common machine learning frameworks. \n",
    "\n",
    "**NOTE:** Chassisml provides two key functionalities: \n",
    "1. Create a Docker container from your model code and push that container image to a Docker registry. This is the default behavior.\n",
    "2. Should you pass valid Modzy credentials as optional parameters, Chassisml will take the container and upload it directly to the Modzy environment you specify. You will notice most of these notebooks deploy the model to one of the Modzy internal development environments.   \n",
    "\n",
    "Can't find the framework you are looking for or need help? Fork this repository and open a PR, we're always interested in growing this example bank! \n",
    "\n",
    "The primary maintainers of Chassis also actively monitor our [Discord Server](https://discord.gg/tdfXFY2y), so feel free to join and ask any questions you might have. We'll be there to respond and help out promptly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example model built in this notebook comes from this [Kaggle competition](https://www.kaggle.com/c/shelter-animal-outcomes). Find the original code from the model used in this notebook [here](https://jovian.ai/aakanksha-ns/shelter-outcome).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chassisml\n",
    "import torch\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as torch_optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from io import StringIO\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter credentials\n",
    "Dockerhub creds and Modzy API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker hub username········\n",
      "docker hub password········\n",
      "modzy api key········\n"
     ]
    }
   ],
   "source": [
    "dockerhub_user = getpass.getpass('docker hub username')\n",
    "dockerhub_pass = getpass.getpass('docker hub password')\n",
    "modzy_api_key = getpass.getpass('modzy api key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (26729, 5) orignal:  (26729, 10)\n",
      "test shape:  (11456, 5) original:  (11456, 8)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train = pd.read_csv('./data/animal-shelter-outcomes/train.csv')\n",
    "test = pd.read_csv('./data/animal-shelter-outcomes/test.csv')\n",
    "\n",
    "# drop irrelevant columns and stack train & test sets\n",
    "train_X = train.drop(columns= ['OutcomeType', 'OutcomeSubtype', 'AnimalID'])\n",
    "Y = train['OutcomeType']\n",
    "test_X = test\n",
    "stacked_df = train_X.append(test_X.drop(columns=['ID']))\n",
    "stacked_df = stacked_df.drop(columns=['DateTime'])\n",
    "\n",
    "# drop columns with many null values\n",
    "for col in stacked_df.columns:\n",
    "    if stacked_df[col].isnull().sum() > 10000:\n",
    "        stacked_df = stacked_df.drop(columns = [col])\n",
    "        \n",
    "# label encoding\n",
    "for col in stacked_df.columns:\n",
    "    if stacked_df.dtypes[col] == \"object\":\n",
    "        stacked_df[col] = stacked_df[col].fillna(\"NA\")\n",
    "    else:\n",
    "        stacked_df[col] = stacked_df[col].fillna(0)\n",
    "    stacked_df[col] = LabelEncoder().fit_transform(stacked_df[col])\n",
    "    \n",
    "# make all variables categorical\n",
    "for col in stacked_df.columns:\n",
    "    stacked_df[col] = stacked_df[col].astype('category')\n",
    "\n",
    "# split train from test again\n",
    "X = stacked_df[0:26729]\n",
    "test_processed = stacked_df[26729:]\n",
    "\n",
    "#check if shape[0] matches original\n",
    "print(\"train shape: \", X.shape, \"orignal: \", train.shape)\n",
    "print(\"test shape: \", test_processed.shape, \"original: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create small sample data csv for testing later\n",
    "sample_test = test[:5]\n",
    "with open(\"./data/animal-shelter-outcomes/sample_data.csv\", \"w\") as sample_data:\n",
    "    sample_test.to_csv(sample_data, index=False, line_terminator=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign encoding target\n",
    "Y = LabelEncoder().fit_transform(Y)\n",
    "\n",
    "# split dataset into train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.10, random_state=0)\n",
    "\n",
    "#categorical embedding for columns having more than two values\n",
    "embedded_cols = {n: len(col.cat.categories) for n,col in X.items() if len(col.cat.categories) > 2}\n",
    "embedded_col_names = embedded_cols.keys()\n",
    "embedding_sizes = [(n_categories, min(50, (n_categories+1)//2)) for _,n_categories in embedded_cols.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShelterOutcomeDataset(Dataset):\n",
    "    def __init__(self, X, Y, embedded_col_names):\n",
    "        X = X.copy()\n",
    "        self.X1 = X.loc[:,embedded_col_names].copy().values.astype(np.int64) #categorical columns\n",
    "        self.X2 = X.drop(columns=embedded_col_names).copy().values.astype(np.float32) #numerical columns\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X1[idx], self.X2[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create torch train and validation sets\n",
    "train_ds = ShelterOutcomeDataset(X_train, y_train, embedded_col_names)\n",
    "valid_ds = ShelterOutcomeDataset(X_val, y_val, embedded_col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure CPU/GPU Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShelterOutcomeModel(nn.Module):\n",
    "    def __init__(self, embedding_sizes, n_cont):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for categories,size in embedding_sizes])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeddings) #length of all embeddings combined\n",
    "        self.n_emb, self.n_cont = n_emb, n_cont\n",
    "        self.lin1 = nn.Linear(self.n_emb + self.n_cont, 200)\n",
    "        self.lin2 = nn.Linear(200, 70)\n",
    "        self.lin3 = nn.Linear(70, 5)\n",
    "        self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
    "        self.bn2 = nn.BatchNorm1d(200)\n",
    "        self.bn3 = nn.BatchNorm1d(70)\n",
    "        self.emb_drop = nn.Dropout(0.6)\n",
    "        self.drops = nn.Dropout(0.3)\n",
    "        \n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = [e(x_cat[:,i]) for i,e in enumerate(self.embeddings)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x2 = self.bn1(x_cont)\n",
    "        x = torch.cat([x, x2], 1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShelterOutcomeModel(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(6, 3)\n",
       "    (1): Embedding(46, 23)\n",
       "    (2): Embedding(1678, 50)\n",
       "    (3): Embedding(411, 50)\n",
       "  )\n",
       "  (lin1): Linear(in_features=127, out_features=200, bias=True)\n",
       "  (lin2): Linear(in_features=200, out_features=70, bias=True)\n",
       "  (lin3): Linear(in_features=70, out_features=5, bias=True)\n",
       "  (bn1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (emb_drop): Dropout(p=0.6, inplace=False)\n",
       "  (drops): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ShelterOutcomeModel(embedding_sizes, 1)\n",
    "model.to(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Optimizer, Training, and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.001, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch_optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim\n",
    "\n",
    "def train_model(model, optim, train_dl):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for x1, x2, y in train_dl:\n",
    "        batch = y.shape[0]\n",
    "        output = model(x1, x2)\n",
    "        y = y.type(torch.LongTensor)     \n",
    "        loss = F.cross_entropy(output, y)   \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "    return sum_loss/total\n",
    "\n",
    "def val_loss(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    for x1, x2, y in valid_dl:\n",
    "        current_batch_size = y.shape[0]\n",
    "        out = model(x1, x2)\n",
    "        y = y.type(torch.LongTensor)\n",
    "        loss = F.cross_entropy(out, y)\n",
    "        sum_loss += current_batch_size*(loss.item())\n",
    "        total += current_batch_size\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        correct += (pred == y).float().sum().item()\n",
    "    print(\"valid loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))\n",
    "    return sum_loss/total, correct/total\n",
    "\n",
    "def train_loop(model, epochs, lr=0.01, wd=0.0):\n",
    "    optim = get_optimizer(model, lr = lr, wd = wd)\n",
    "    for i in range(epochs): \n",
    "        loss = train_model(model, optim, train_dl)\n",
    "        print(\"training loss: \", loss)\n",
    "        val_loss(model, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size,shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, torch.device(\"cpu\"))\n",
    "valid_dl = DeviceDataLoader(valid_dl, torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  0.9865190627807234\n",
      "valid loss 0.891 and accuracy 0.623\n",
      "training loss:  0.9513287070109118\n",
      "valid loss 0.869 and accuracy 0.626\n",
      "training loss:  0.9488261960890351\n",
      "valid loss 0.883 and accuracy 0.629\n",
      "training loss:  0.9475331834712851\n",
      "valid loss 0.872 and accuracy 0.633\n",
      "training loss:  0.9390505436135163\n",
      "valid loss 0.882 and accuracy 0.634\n",
      "training loss:  0.954956340084133\n",
      "valid loss 0.876 and accuracy 0.631\n",
      "training loss:  0.951382885214733\n",
      "valid loss 0.867 and accuracy 0.634\n",
      "training loss:  0.9364405162991738\n",
      "valid loss 0.887 and accuracy 0.624\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, epochs=8, lr=0.05, wd=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = ShelterOutcomeDataset(test_processed, np.zeros(len(test_processed)), embedded_col_names)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for x1,x2,y in test_dl:\n",
    "        out = model(x1, x2)\n",
    "        prob = F.softmax(out, dim=1)\n",
    "        preds.append(prob)\n",
    "final_probs = [item for sublist in preds for item in sublist]\n",
    "print(final_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model\n",
    "Initialize anything here that should persist across inference runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tabular = model\n",
    "model.eval()\n",
    "\n",
    "embedded_columns = embedded_col_names\n",
    "output_names = [\"ID\", \"Adoption\", \"Died\", \"Euthanasia\", \"Return_to_owner\", \"Transfer\"]\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write process function\n",
    "\n",
    "* Must take bytes as input\n",
    "* Preprocess bytes, run inference, postprocess model output, return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(csv, embedded_cols):\n",
    "    \n",
    "    # drop ID and date columns\n",
    "    csv = csv.drop(columns=[\"ID\", \"DateTime\", \"Name\"])\n",
    "    \n",
    "    # drop columns with many null values\n",
    "    for col in csv.columns:\n",
    "        if csv[col].isnull().sum() > 10000:\n",
    "            csv = csv.drop(columns = [col])\n",
    "\n",
    "    # label encoding\n",
    "    for col in csv.columns:\n",
    "        if csv.dtypes[col] == \"object\":\n",
    "            csv[col] = csv[col].fillna(\"NA\")\n",
    "        else:\n",
    "            csv[col] = csv[col].fillna(0)\n",
    "        csv[col] = LabelEncoder().fit_transform(csv[col])\n",
    "\n",
    "    # make all variables categorical\n",
    "    for col in stacked_df.columns:\n",
    "        csv[col] = csv[col].astype('category')\n",
    "        \n",
    "    # convert csv to dataloader\n",
    "    shelter_ds = ShelterOutcomeDataset(csv, np.zeros(len(csv)), embedded_cols)\n",
    "    test_dl = DataLoader(shelter_ds, batch_size=1)\n",
    "        \n",
    "    return test_dl\n",
    "    \n",
    "def postprocess(predictions_df, output_csv):\n",
    "    \n",
    "    # fill in output\n",
    "    output_csv['Adoption'] = [float(t[0]) for t in predictions_df]\n",
    "    output_csv['Died'] = [float(t[1]) for t in predictions_df]\n",
    "    output_csv['Euthanasia'] = [float(t[2]) for t in predictions_df]\n",
    "    output_csv['Return_to_owner'] = [float(t[3]) for t in predictions_df]\n",
    "    output_csv['Transfer'] = [float(t[4]) for t in predictions_df]\n",
    "    \n",
    "    return output_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(input_bytes):\n",
    "    \n",
    "    # preprocess\n",
    "    df = pd.read_csv(StringIO(str(input_bytes, \"utf-8\")))\n",
    "    df = preprocess(df, embedded_columns)\n",
    "    \n",
    "    # run inference\n",
    "    preds = []\n",
    "    for x1, x2, _  in df: \n",
    "        out = model(x1, x2)\n",
    "        prob = F.softmax(out, dim=1)\n",
    "        preds.append(prob)\n",
    "    final_probs = [item for sublist in preds for item in sublist] \n",
    "\n",
    "    # postprocess\n",
    "    output_skeleton = pd.DataFrame(0, index=np.arange(len(final_probs)), columns=output_column_names)\n",
    "    output_skeleton[\"ID\"] = [i+1 for i in range(len(final_probs))]\n",
    "    final_output = postprocess(final_probs, output_skeleton)\n",
    "    \n",
    "    inference_result = final_output.to_json()\n",
    "\n",
    "    structured_output = {\n",
    "        \"data\": {\n",
    "            \"result\": inference_result,\n",
    "            \"explanation\": None,\n",
    "            \"drift\": None,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return structured_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Chassis Client\n",
    "We'll use this to interact with the Chassis service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "chassis_client = chassisml.ChassisClient(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and test Chassis model\n",
    "* Requires `process_fn` defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"data\":{\"result\":\"{\\\\\"ID\\\\\":{\\\\\"0\\\\\":1,\\\\\"1\\\\\":2,\\\\\"2\\\\\":3,\\\\\"3\\\\\":4,\\\\\"4\\\\\":5},\\\\\"Adoption\\\\\":{\\\\\"0\\\\\":0.0205119159,\\\\\"1\\\\\":0.728466332,\\\\\"2\\\\\":0.0652435422,\\\\\"3\\\\\":0.0106766773,\\\\\"4\\\\\":0.4149729609},\\\\\"Died\\\\\":{\\\\\"0\\\\\":0.0118920719,\\\\\"1\\\\\":0.0022707784,\\\\\"2\\\\\":0.0102348896,\\\\\"3\\\\\":0.0128209479,\\\\\"4\\\\\":0.0086779036},\\\\\"Euthanasia\\\\\":{\\\\\"0\\\\\":0.0620467477,\\\\\"1\\\\\":0.0077749281,\\\\\"2\\\\\":0.0379733928,\\\\\"3\\\\\":0.0512745008,\\\\\"4\\\\\":0.0421656035},\\\\\"Return_to_owner\\\\\":{\\\\\"0\\\\\":0.0594031587,\\\\\"1\\\\\":0.0341950096,\\\\\"2\\\\\":0.012345545,\\\\\"3\\\\\":0.0251460969,\\\\\"4\\\\\":0.0532071441},\\\\\"Transfer\\\\\":{\\\\\"0\\\\\":0.8461461067,\\\\\"1\\\\\":0.2272929996,\\\\\"2\\\\\":0.8742026091,\\\\\"3\\\\\":0.9000817537,\\\\\"4\\\\\":0.4809763134}}\",\"explanation\":null,\"drift\":null}}'\n"
     ]
    }
   ],
   "source": [
    "# create Chassis model\n",
    "chassis_model = chassis_client.create_model(process_fn=process)\n",
    "\n",
    "# test Chassis model (can pass filepath, bufferedreader, bytes, or text here):\n",
    "sample_filepath = \"./data/animal-shelter-outcomes/sample_data.csv\"\n",
    "results = chassis_model.test(sample_filepath)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test job... Ok!\n",
      "{'model_output': 'b\\'{\"data\":{\"result\":\"{\\\\\\\\\"ID\\\\\\\\\":{\\\\\\\\\"0\\\\\\\\\":1,\\\\\\\\\"1\\\\\\\\\":2,\\\\\\\\\"2\\\\\\\\\":3,\\\\\\\\\"3\\\\\\\\\":4,\\\\\\\\\"4\\\\\\\\\":5},\\\\\\\\\"Adoption\\\\\\\\\":{\\\\\\\\\"0\\\\\\\\\":0.0205119159,\\\\\\\\\"1\\\\\\\\\":0.728466332,\\\\\\\\\"2\\\\\\\\\":0.0652435422,\\\\\\\\\"3\\\\\\\\\":0.0106766783,\\\\\\\\\"4\\\\\\\\\":0.4149729609},\\\\\\\\\"Died\\\\\\\\\":{\\\\\\\\\"0\\\\\\\\\":0.0118920719,\\\\\\\\\"1\\\\\\\\\":0.0022707784,\\\\\\\\\"2\\\\\\\\\":0.0102348896,\\\\\\\\\"3\\\\\\\\\":0.0128209479,\\\\\\\\\"4\\\\\\\\\":0.0086779092},\\\\\\\\\"Euthanasia\\\\\\\\\":{\\\\\\\\\"0\\\\\\\\\":0.0620467477,\\\\\\\\\"1\\\\\\\\\":0.0077749281,\\\\\\\\\"2\\\\\\\\\":0.0379733928,\\\\\\\\\"3\\\\\\\\\":0.0512745008,\\\\\\\\\"4\\\\\\\\\":0.0421656109},\\\\\\\\\"Return_to_owner\\\\\\\\\":{\\\\\\\\\"0\\\\\\\\\":0.0594031587,\\\\\\\\\"1\\\\\\\\\":0.0341950096,\\\\\\\\\"2\\\\\\\\\":0.0123455506,\\\\\\\\\"3\\\\\\\\\":0.0251460969,\\\\\\\\\"4\\\\\\\\\":0.0532071516},\\\\\\\\\"Transfer\\\\\\\\\":{\\\\\\\\\"0\\\\\\\\\":0.8461461067,\\\\\\\\\"1\\\\\\\\\":0.2272929847,\\\\\\\\\"2\\\\\\\\\":0.8742026091,\\\\\\\\\"3\\\\\\\\\":0.9000817537,\\\\\\\\\"4\\\\\\\\\":0.480976373}}\",\"explanation\":null,\"drift\":null}}\\'\\n'}\n"
     ]
    }
   ],
   "source": [
    "# test environment and model within Chassis service, must pass filepath here:\n",
    "test_env_result = chassis_model.test_env(sample_filepath)\n",
    "print(test_env_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish model to Modzy\n",
    "Need to provide model name, model version, Dockerhub credentials, and required Modzy info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting build job... Ok!\n"
     ]
    }
   ],
   "source": [
    "MODZY_URL = \"https://integration.modzy.engineering/api\"\n",
    "\n",
    "response = chassis_model.publish(\n",
    "    model_name=\"PyTorch Tabular Data Animal Shelter Outcome Predictions\",\n",
    "    model_version=\"0.0.2\",\n",
    "    registry_user=dockerhub_user,\n",
    "    registry_pass=dockerhub_pass,\n",
    "    modzy_sample_input_path=sample_filepath,\n",
    "    modzy_api_key=modzy_api_key,\n",
    "    modzy_url=MODZY_URL\n",
    ")\n",
    "\n",
    "job_id = response.get('job_id')\n",
    "final_status = chassis_client.block_until_complete(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model URL: https://integration.modzy.engineering/models/pcmfspdnml/0.0.2\n"
     ]
    }
   ],
   "source": [
    "if chassis_client.get_job_status(job_id)[\"result\"] is not None:\n",
    "    print(\"New model URL: {}\".format(chassis_client.get_job_status(job_id)[\"result\"][\"container_url\"]))\n",
    "else:\n",
    "    print(\"Chassis job failed \\n\\n {}\".format(chassis_client.get_job_status(job_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run sample job\n",
    "Submit inference job to our newly-deploy model running on Modzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApiObject({\n",
      "  \"data\": {\n",
      "    \"drift\": null,\n",
      "    \"explanation\": null,\n",
      "    \"result\": \"{\\\"ID\\\":{\\\"0\\\":1,\\\"1\\\":2,\\\"2\\\":3,\\\"3\\\":4,\\\"4\\\":5},\\\"Adoption\\\":{\\\"0\\\":0.0205119159,\\\"1\\\":0.728466332,\\\"2\\\":0.0652435347,\\\"3\\\":0.0106766829,\\\"4\\\":0.4149729908},\\\"Died\\\":{\\\"0\\\":0.0118920719,\\\"1\\\":0.0022707784,\\\"2\\\":0.0102348896,\\\"3\\\":0.0128209479,\\\"4\\\":0.0086779045},\\\"Euthanasia\\\":{\\\"0\\\":0.0620467477,\\\"1\\\":0.0077749281,\\\"2\\\":0.0379733928,\\\"3\\\":0.051274512,\\\"4\\\":0.0421656109},\\\"Return_to_owner\\\":{\\\"0\\\":0.0594031587,\\\"1\\\":0.0341950096,\\\"2\\\":0.012345545,\\\"3\\\":0.0251460969,\\\"4\\\":0.0532071367},\\\"Transfer\\\":{\\\"0\\\":0.8461461067,\\\"1\\\":0.2272929847,\\\"2\\\":0.8742026091,\\\"3\\\":0.9000817537,\\\"4\\\":0.480976373}}\"\n",
      "  }\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from modzy import ApiClient\n",
    "\n",
    "client = ApiClient(base_url='https://integration.modzy.engineering/api', api_key=modzy_api_key)\n",
    "\n",
    "input_name = final_status['result']['inputs'][0]['name']\n",
    "model_id = final_status['result'].get(\"model\").get(\"modelId\")\n",
    "model_version = final_status['result'].get(\"version\")\n",
    "\n",
    "inference_job = client.jobs.submit_file(model_id, model_version, {input_name: sample_filepath})\n",
    "inference_job_result = client.results.block_until_complete(inference_job, timeout=None)\n",
    "inference_job_results_json = inference_job_result.get_first_outputs()['results.json']\n",
    "print(inference_job_results_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Died</th>\n",
       "      <th>Euthanasia</th>\n",
       "      <th>Return_to_owner</th>\n",
       "      <th>Transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.020512</td>\n",
       "      <td>0.011892</td>\n",
       "      <td>0.062047</td>\n",
       "      <td>0.059403</td>\n",
       "      <td>0.846146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.728466</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>0.007775</td>\n",
       "      <td>0.034195</td>\n",
       "      <td>0.227293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.065244</td>\n",
       "      <td>0.010235</td>\n",
       "      <td>0.037973</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.874203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.051275</td>\n",
       "      <td>0.025146</td>\n",
       "      <td>0.900082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.414973</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>0.042166</td>\n",
       "      <td>0.053207</td>\n",
       "      <td>0.480976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Adoption      Died  Euthanasia  Return_to_owner  Transfer\n",
       "0   1  0.020512  0.011892    0.062047         0.059403  0.846146\n",
       "1   2  0.728466  0.002271    0.007775         0.034195  0.227293\n",
       "2   3  0.065244  0.010235    0.037973         0.012346  0.874203\n",
       "3   4  0.010677  0.012821    0.051275         0.025146  0.900082\n",
       "4   5  0.414973  0.008678    0.042166         0.053207  0.480976"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.read_json(inference_job_results_json[\"data\"][\"result\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95ab8d3bdd708a5b71676285742277315a30b0df1ed91c8905076616709c59d5"
  },
  "kernelspec": {
   "display_name": "chassis-demo",
   "language": "python",
   "name": "chassis-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
