{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chassisml Example Notebooks\n",
    "Welcome to the examples section for [Chassis.ml](https://chassis.ml), which contains notebooks that leverage Chassisml to auto-containerize models built using the most common machine learning frameworks. \n",
    "\n",
    "**NOTE:** Chassisml provides two key functionalities: \n",
    "1. Create a Docker container from your model code and push that container image to a Docker registry. This is the default behavior.\n",
    "2. Should you pass valid Modzy credentials as optional parameters, Chassisml will take the container and upload it directly to the Modzy environment you specify. You will notice most of these notebooks deploy the model to one of the Modzy internal development environments.   \n",
    "\n",
    "Can't find the framework you are looking for or need help? Fork this repository and open a PR, we're always interested in growing this example bank! \n",
    "\n",
    "The primary maintainers of Chassis also actively monitor our [Discord Server](https://discord.gg/tdfXFY2y), so feel free to join and ask any questions you might have. We'll be there to respond and help out promptly. ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chassisml\n",
    "import pickle\n",
    "import cv2\n",
    "import torch\n",
    "import getpass\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter credentials\n",
    "Dockerhub creds and Modzy API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker hub username········\n",
      "docker hub password········\n",
      "modzy api key········\n"
     ]
    }
   ],
   "source": [
    "dockerhub_user = getpass.getpass('docker hub username')\n",
    "dockerhub_pass = getpass.getpass('docker hub password')\n",
    "modzy_api_key = getpass.getpass('modzy api key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model, data transform object, and labels\n",
    "Initialize anything here that should persist across inference runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "labels = pickle.load(open('./data/imagenet_labels.pkl','rb'))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])        \n",
    "\n",
    "# use GPU:\n",
    "device = 'cuda'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write batch process function\n",
    "\n",
    "* Must take list[bytes] input\n",
    "* Preprocess all inputs, run inference in batch, postprocess batch model output, return list of formatted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process(inputs):\n",
    "    \n",
    "    # preprocess list of inputs\n",
    "    images = []\n",
    "    for input_bytes in inputs:\n",
    "        decoded = cv2.imdecode(np.frombuffer(input_bytes, np.uint8), -1)\n",
    "        resized = cv2.resize(decoded, (224, 224)).reshape((1,224,224,3))\n",
    "        images.append(resized)\n",
    "    images_arr = np.concatenate(images)\n",
    "    batch_t = torch.stack(tuple(transform(i) for i in images_arr), dim=0).to(device)\n",
    "\n",
    "    # run batch inference and softmax\n",
    "    output = model(batch_t)\n",
    "    probs = torch.nn.functional.softmax(output, dim=1)\n",
    "    softmax_preds = probs.detach().cpu().numpy()\n",
    "    \n",
    "    # postprocess\n",
    "    all_formatted_results = []\n",
    "    for preds in softmax_preds: \n",
    "        indices = np.argsort(preds)[::-1]\n",
    "        classes = [labels[idx] for idx in indices[:5]]\n",
    "        scores = [float(preds[idx]) for idx in indices[:5]]\n",
    "        preds = [{\"class\": \"{}\".format(label), \"score\": round(float(score),3)} for label, score in zip(classes, scores)]\n",
    "        preds.sort(key = lambda x: x[\"score\"],reverse=True)\n",
    "        results = {\"classPredictions\": preds}\n",
    "        all_formatted_results.append(results)\n",
    "    \n",
    "    # output list of formatted results\n",
    "    return all_formatted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Chassis Client\n",
    "We'll use this to interact with the Chassis service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chassis_client = chassisml.ChassisClient(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and test Chassis model\n",
    "* Requires at least one of single input `process_fn` or batch input `batch_process_fn` defined above\n",
    "    * If you provide `batch_process_fn`, you must also provide a `batch_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"classPredictions\":[{\"class\":\"airliner\",\"score\":0.606},{\"class\":\"crane\",\"score\":0.11},{\"class\":\"wing\",\"score\":0.103},{\"class\":\"chain saw, chainsaw\",\"score\":0.07},{\"class\":\"aircraft carrier, carrier, flattop, attack aircraft carrier\",\"score\":0.048}]}'\n"
     ]
    }
   ],
   "source": [
    "# create Chassis model\n",
    "chassis_model = chassis_client.create_model(batch_process_fn=batch_process,batch_size=4)\n",
    "\n",
    "# test Chassis model (can pass filepath, bufferedreader, bytes, or text here):\n",
    "sample_filepath = './data/airplane.jpg'\n",
    "results = chassis_model.test(sample_filepath)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'{\"classPredictions\":[{\"class\":\"airliner\",\"score\":0.606},{\"class\":\"crane\",\"score\":0.11},{\"class\":\"wing\",\"score\":0.103},{\"class\":\"chain saw, chainsaw\",\"score\":0.07},{\"class\":\"aircraft carrier, carrier, flattop, attack aircraft carrier\",\"score\":0.048}]}', b'{\"classPredictions\":[{\"class\":\"airliner\",\"score\":0.606},{\"class\":\"crane\",\"score\":0.11},{\"class\":\"wing\",\"score\":0.103},{\"class\":\"chain saw, chainsaw\",\"score\":0.07},{\"class\":\"aircraft carrier, carrier, flattop, attack aircraft carrier\",\"score\":0.048}]}', b'{\"classPredictions\":[{\"class\":\"airliner\",\"score\":0.606},{\"class\":\"crane\",\"score\":0.11},{\"class\":\"wing\",\"score\":0.103},{\"class\":\"chain saw, chainsaw\",\"score\":0.07},{\"class\":\"aircraft carrier, carrier, flattop, attack aircraft carrier\",\"score\":0.048}]}', b'{\"classPredictions\":[{\"class\":\"airliner\",\"score\":0.606},{\"class\":\"crane\",\"score\":0.11},{\"class\":\"wing\",\"score\":0.103},{\"class\":\"chain saw, chainsaw\",\"score\":0.07},{\"class\":\"aircraft carrier, carrier, flattop, attack aircraft carrier\",\"score\":0.048}]}']\n"
     ]
    }
   ],
   "source": [
    "# test batch locally\n",
    "results = chassis_model.test_batch(sample_filepath)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish model to Modzy\n",
    "Need to provide model name, model version, Dockerhub credentials, required Modzy info, AND specify gpu=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting build job... Ok!\n"
     ]
    }
   ],
   "source": [
    "MODZY_URL = \"https://integration.modzy.engineering/api\"\n",
    "\n",
    "response = chassis_model.publish(model_name=\"Torch Imagenet GPU\",model_version=\"0.0.1\",\n",
    "                     registry_user=dockerhub_user,registry_pass=dockerhub_pass,\n",
    "                     modzy_sample_input_path=sample_filepath,\n",
    "                     modzy_api_key=modzy_api_key,modzy_url=MODZY_URL, gpu=True)\n",
    "\n",
    "job_id = response.get('job_id')\n",
    "final_status = chassis_client.block_until_complete(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run sample job\n",
    "Submit inference job to our newly-deploy model running on Modzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modzy import ApiClient\n",
    "\n",
    "client = ApiClient(base_url='https://integration.modzy.engineering/api', api_key=modzy_api_key)\n",
    "\n",
    "input_name = final_status['result']['inputs'][0]['name']\n",
    "model_id = final_status['result'].get(\"model\").get(\"modelId\")\n",
    "model_version = final_status['result'].get(\"version\")\n",
    "\n",
    "# submit 16 inputs\n",
    "sources = {\"input_{}\".format(i): {input_name: sample_filepath} for i in range(16)}\n",
    "inference_job = client.jobs.submit_file(model_id, model_version, sources)\n",
    "inference_job_result = client.results.block_until_complete(inference_job, timeout=None)\n",
    "print(inference_job_result[\"results\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95ab8d3bdd708a5b71676285742277315a30b0df1ed91c8905076616709c59d5"
  },
  "kernelspec": {
   "display_name": "chassis-demo-1",
   "language": "python",
   "name": "chassis-demo-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
